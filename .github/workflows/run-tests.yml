name: Run BDD Tests, Upload to Datadog, and Generate Allure Report

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

# Update permissions for GitHub Pages deployment and potentially other actions
permissions:
  contents: write
  pages: write
  id-token: write

env:
  ALLURE_RESULTS_DIR: allure-results
  ALLURE_REPORT_DIR: allure-report
  JUNIT_RESULTS_DIR: junit-results # Directory for JUnit XML reports
  DATADOG_SERVICE_NAME: flight-search-tests # Unique service name for this repo
  DATADOG_SITE: datadoghq.eu # Change this if your site is different (e.g., datadoghq.com)

jobs:
  behave-tests:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18' # Or a recent LTS version

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Install Datadog CI CLI
      run: npm install --global @datadog/datadog-ci

    - name: Run Behave Tests (JUnit & Allure)
      run: |
        # Create directories if they don't exist
        mkdir -p ${{ env.JUNIT_RESULTS_DIR }}
        mkdir -p ${{ env.ALLURE_RESULTS_DIR }}
        # Run behave with both JUnit and Allure formatters
        # Removed ddtrace-run, added --junit flag
        behave --junit --junit-directory ${{ env.JUNIT_RESULTS_DIR }} -f allure_behave.formatter:AllureFormatter -o ${{ env.ALLURE_RESULTS_DIR }} features/
      continue-on-error: true # Continue even if tests fail to allow report upload

    - name: Upload JUnit Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: junit-results
        path: ${{ env.JUNIT_RESULTS_DIR }}
        retention-days: 1

    - name: Upload Test Results to Datadog
      if: always() # Run this step even if previous steps fail
      env:
        DD_API_KEY: ${{ secrets.DD_API_KEY }}
        # DD_SITE is already set in the global env
      run: |
        datadog-ci junit upload --service ${{ env.DATADOG_SERVICE_NAME }} ${{ env.JUNIT_RESULTS_DIR }}

    - name: Generate Allure Report
      if: always()
      run: |
        # Download and extract Allure
        curl -o allure-commandline.tgz -OLs https://repo.maven.apache.org/maven2/io/qameta/allure/allure-commandline/2.24.0/allure-commandline-2.24.0.tgz
        tar -zxvf allure-commandline.tgz
        
        # Run Allure directly from the extracted directory
        # This preserves the required directory structure
        ./allure-2.24.0/bin/allure generate ${{ env.ALLURE_RESULTS_DIR }} -o ${{ env.ALLURE_REPORT_DIR }} --clean
        
        # Clean up
        rm -rf allure-commandline.tgz

    - name: Archive Allure Report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: allure-report
        path: ${{ env.ALLURE_REPORT_DIR }}
        retention-days: 1

  # Separate job for GitHub Pages deployment
  deploy-pages:
    runs-on: ubuntu-latest
    needs: behave-tests
    if: always()
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        persist-credentials: true

    - name: Download Allure Report
      uses: actions/download-artifact@v4
      with:
        name: allure-report
        path: ${{ env.ALLURE_REPORT_DIR }}

    - name: Download JUnit Results
      uses: actions/download-artifact@v4
      with:
        name: junit-results  # Make sure this matches what was uploaded in the behave-tests job
        path: ${{ env.JUNIT_RESULTS_DIR }}
        
    - name: Deploy to GitHub Pages
      run: |
        git config --global user.name 'github-actions[bot]'
        git config --global user.email 'github-actions[bot]@users.noreply.github.com'
        git checkout --orphan gh-pages-temp
        git rm -rf .
        
        # Copy Allure report
        cp -r ${{ env.ALLURE_REPORT_DIR }}/* .
        
        # ===== Generate metrics.json using actual test results =====
        echo "Generating metrics.json for Sanity Test Hub integration..."
        
        # Check if JUnit files exist
        if [ -d "${{ env.JUNIT_RESULTS_DIR }}" ] && [ "$(ls -A ${{ env.JUNIT_RESULTS_DIR }})" ]; then
          echo "Found JUnit XML files - parsing results"
          
          # Display file contents for debugging
          echo "JUnit XML files found:"
          ls -la ${{ env.JUNIT_RESULTS_DIR }}
          
          # Parse with more reliable methods
          TOTAL_TESTS=$(grep -c "<testcase " ${{ env.JUNIT_RESULTS_DIR }}/*.xml || echo 0)
          echo "Total tests found: $TOTAL_TESTS"
          
          FAILED_TESTS=$(grep -c "<failure" ${{ env.JUNIT_RESULTS_DIR }}/*.xml || echo 0)
          echo "Failed tests found: $FAILED_TESTS"
          
          PASSED_TESTS=$((TOTAL_TESTS - FAILED_TESTS))
          echo "Passed tests calculated: $PASSED_TESTS"
          
          # Search for @critical tags in the XML content
          CRITICAL_TESTS=$(grep -c "@critical" ${{ env.JUNIT_RESULTS_DIR }}/*.xml || echo 0)
          echo "Critical tests found: $CRITICAL_TESTS"
          
          # Calculate pass rate with simple integer division
          if [ $TOTAL_TESTS -eq 0 ]; then
            PASS_RATE=0
          else
            PASS_RATE=$((PASSED_TESTS * 100 / TOTAL_TESTS))
          fi
        else
          echo "Warning: No JUnit files found. Setting all metrics to 0."
          # Set all metrics to 0 if no test data available
          TOTAL_TESTS=0
          PASSED_TESTS=0
          FAILED_TESTS=0
          CRITICAL_TESTS=0
          PASS_RATE=0
        fi
        
        # Format timestamp
        TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        
        # Create metrics.json file with proper syntax
        echo "{" > metrics.json
        echo "  \"timestamp\": \"$TIMESTAMP\"," >> metrics.json
        echo "  \"total_tests\": $TOTAL_TESTS," >> metrics.json
        echo "  \"passed_tests\": $PASSED_TESTS," >> metrics.json
        echo "  \"failed_tests\": $FAILED_TESTS," >> metrics.json
        echo "  \"pass_rate\": $PASS_RATE," >> metrics.json
        echo "  \"duration_seconds\": 0," >> metrics.json
        echo "  \"critical_tests_count\": $CRITICAL_TESTS," >> metrics.json
        echo "  \"run_id\": \"${{ github.run_id }}\"," >> metrics.json
        echo "  \"repository\": \"${{ github.repository }}\"," >> metrics.json
        echo "  \"branch\": \"${{ github.ref }}\"" >> metrics.json
        echo "}" >> metrics.json
        
        echo "Created metrics.json:"
        cat metrics.json
        # ===== End of metrics.json generation =====
        
        # Create a redirect from the root to the Allure report index
        echo '<!DOCTYPE html>
        <html>
        <head>
          <meta http-equiv="refresh" content="0; url=index.html">
        </head>
        <body>
          <p>Redirecting to test report...</p>
        </body>
        </html>' > dashboard.html
        
        touch .nojekyll
        git add .
        git commit -m "Update Allure report and metrics"
        git push -f origin gh-pages-temp:gh-pages
